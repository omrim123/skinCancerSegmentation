









































Epoch 1/15:  47%|████████████████████████████████████████████                                                  | 1216/2594 [02:52<03:01,  7.61img/s, loss (batch)=0.962]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x12ef416c0>
Traceback (most recent call last):
  File "/opt/anaconda3/envs/DL_project/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1478, in __del__
    def __del__(self):
  File "/opt/anaconda3/envs/DL_project/lib/python3.11/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 20998) is killed by signal: Interrupt: 2.
Epoch 1/15:  47%|████████████████████████████████████████████                                                  | 1216/2594 [02:55<03:18,  6.94img/s, loss (batch)=0.962]
Traceback (most recent call last):
  File "/Users/nathan/Documents/Semester6/DeepLearning/DL_Project/skinCancerSegmentation/train.py", line 337, in <module>
    train_model(
  File "/Users/nathan/Documents/Semester6/DeepLearning/DL_Project/skinCancerSegmentation/train.py", line 189, in train_model
    loss.backward()
  File "/opt/anaconda3/envs/DL_project/lib/python3.11/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/opt/anaconda3/envs/DL_project/lib/python3.11/site-packages/torch/autograd/__init__.py", line 266, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt